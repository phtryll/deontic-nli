from source.cfg import CFG
from source.cfg_utils import join
from source.generate_utils import *

def generate_examples(grammar: CFG, num_examples: int = 20, print_tree: bool = False) -> None:
    """Prints examples generated by a grammar."""

    # Generate examples
    for _ in range(num_examples):

        # Generate a random tree
        tree = grammar.generate(False)

        # Get the terminal yield of the tree
        tokens = tree.output()

        # See the tree structure and the yield
        if print_tree:
            print("sampled tree:", tree) # Print the tree structure
            print("yield:", tokens) # Print the yield (list of tokens)
        
        # Otherwise print the examples
        else:
            text = join(tokens) # Join the tokens into a sentence
            print(text) # Print the resulting sentence


def generate_rules(prompts: Dict[str, List[str]], tokenizer: Any, model: Any, top_k: int, labels: Dict[str, List[str]]) -> None:
    """
    Generate rules for specific non-terminal symbols for lexical diversity.
    Uses generate_lexical_pool and format_lexical_pool to handle multi-mask slots.
    
    -   prompts (Dict[str, List[str]]): Map from category names to lists of mask-containing prompts.
    -   tokenizer (Any): HuggingFace tokenizer for a masked LLM.
    -   model (Any): HuggingFace masked language model instance.
    -   top_k (int): Number of top joint candidates to retain per category.
    -   labels (Dict[str, List[str]]): Map from category names to their slot-label lists.
    """
    
    # Generate lexical items pool
    pool = generate_lexical_pool(prompts, tokenizer, model, top_k=top_k)

    # Format the lexical pool into slot-mapped dictionaries
    formatted_pools = format_lexical_pool(pool, labels)

    # Generate and print rules for each slot dictionary
    for slot_dict in formatted_pools:
        rules = format_rules(slot_dict)
        for rule in rules:
            print(rule)
